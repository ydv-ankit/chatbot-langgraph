{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1e8581",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "from langgraph.graph import StateGraph, add_messages, END\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_tavily import TavilySearch\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from uuid import uuid4\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59577511",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc3b6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model = \"gpt-4o-mini\")\n",
    "search_tool = TavilySearch(max_results=4)\n",
    "tools = [search_tool]\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1393cebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools = tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e3ac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "async def model(state: State):\n",
    "    result = await llm_with_tools.ainvoke(state['messages'])\n",
    "    return {\n",
    "        \"messages\": [result]\n",
    "    }\n",
    "\n",
    "async def tools_router(state: State):\n",
    "    last_message = state['messages'][-1]\n",
    "\n",
    "    if (hasattr(last_message, \"tool_calls\") and len(last_message.tool_calls) > 0):\n",
    "        return \"tool_node\"\n",
    "    else:\n",
    "        return END\n",
    "\n",
    "    \n",
    "async def tool_node(state: State):\n",
    "    \"\"\"Custom tool node that handles tool calls from LLM\"\"\"\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "\n",
    "    tool_messages = []\n",
    "\n",
    "    # process each tool call\n",
    "    for tool_call in tool_calls:\n",
    "        tool_name = tool_call[\"name\"]\n",
    "        tool_args = tool_call[\"args\"]\n",
    "        tool_id = tool_call[\"id\"]\n",
    "\n",
    "        if tool_name == \"tavily_search\":\n",
    "            search_results = await search_tool.ainvoke(tool_args)\n",
    "            tool_message = ToolMessage(\n",
    "                content=str(search_results),\n",
    "                tool_call_id = tool_id,\n",
    "                name = tool_name\n",
    "            )\n",
    "            tool_messages.append(tool_message)\n",
    "    \n",
    "    return {\n",
    "        \"messages\": tool_messages\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f704287",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"model\", model)\n",
    "graph_builder.add_node(\"tool_node\", tool_node)\n",
    "graph_builder.set_entry_point(\"model\")\n",
    "\n",
    "graph_builder.add_edge(\"tool_node\", \"model\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"model\",\n",
    "    tools_router,\n",
    "    {\n",
    "        \"tool_node\": \"tool_node\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa385ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        graph.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84fe2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_id = uuid4()\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": thread_id\n",
    "    }\n",
    "}\n",
    "\n",
    "response = await graph.ainvoke({\n",
    "    \"messages\": [HumanMessage(content=\"What's current weather in bangkok, thailand?\")]\n",
    "}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f436f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_id = uuid4()\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": thread_id\n",
    "    }\n",
    "}\n",
    "\n",
    "async for event in graph.astream_events({\n",
    "    \"messages\": [HumanMessage(content=\"What's current weather in bangkok, thailand?\")]\n",
    "}, config=config, version=\"v2\"):\n",
    "    if event['event'] == \"on_chat_model_stream\":\n",
    "        print(event['data']['chunk'].content, end = \"\", flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef7864c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
